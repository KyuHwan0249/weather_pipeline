version: "3.9"

x-airflow-build: &airflow-build
  build:
    context: ./airflow
  image: custom-airflow:latest

services:
  #############################################################
  # 1) ORIGIN DATA GENERATOR
  #############################################################
  create-origin-data-app:
    build: ./create-origin-data-app
    container_name: create-origin-data-app
    volumes:
      - ./kaggle-data:/app/data/kaggle
      - ./origin-data:/app/data/output
      - ./create-origin-data-app:/app
    environment:
      PYTHONUNBUFFERED: 1
      ORIGIN_INPUT: ${ORIGIN_INPUT}
      ORIGIN_OUTPUT: ${ORIGIN_OUTPUT}
      DROP_INTERVAL: ${DROP_INTERVAL}
      ROW_INTERVAL: ${ROW_INTERVAL}
      ERROR_RATE: ${ERROR_RATE}
    restart: on-failure
    depends_on:
      - producer-app
    networks:
      - project-net

  #############################################################
  # 2) KAFKA BROKER CLUSTER
  #############################################################

  kafka-1:
    image: apache/kafka:3.7.0
    container_name: kafka-1
    hostname: kafka-1
    ports:
      - "9092:9092"
    networks:
      - project-net
    volumes:
      - ./kafka/server-1.properties:/opt/kafka/config/kraft/server.properties
      - ./kafka/data/broker1:/var/lib/kafka/data
    environment:
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    command: ["/opt/kafka/bin/kafka-server-start.sh", "/opt/kafka/config/kraft/server.properties"]
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/kafka-1/9092"]
      interval: 5s
      timeout: 5s
      retries: 10

  kafka-2:
    image: apache/kafka:3.7.0
    container_name: kafka-2
    hostname: kafka-2
    ports:
      - "9093:9092"
    networks:
      - project-net
    volumes:
      - ./kafka/server-2.properties:/opt/kafka/config/kraft/server.properties
      - ./kafka/data/broker2:/var/lib/kafka/data
    environment:
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    command: ["/opt/kafka/bin/kafka-server-start.sh", "/opt/kafka/config/kraft/server.properties"]
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/kafka-1/9092"]
      interval: 5s
      timeout: 5s
      retries: 10

  kafka-3:
    image: apache/kafka:3.7.0
    container_name: kafka-3
    hostname: kafka-3
    ports:
      - "9094:9092"
    networks:
      - project-net
    volumes:
      - ./kafka/server-3.properties:/opt/kafka/config/kraft/server.properties
      - ./kafka/data/broker3:/var/lib/kafka/data
    environment:
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    command: ["/opt/kafka/bin/kafka-server-start.sh", "/opt/kafka/config/kraft/server.properties"]
    healthcheck:
      test: ["CMD", "bash", "-c", "echo > /dev/tcp/kafka-1/9092"]
      interval: 5s
      timeout: 5s
      retries: 10

  #############################################################
  # 3) KAFKA INIT (Create Topics Only)
  #############################################################
  kafka-init:
    image: apache/kafka:3.7.0
    container_name: kafka-init
    networks:
      - project-net
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    entrypoint: ["/bin/bash", "-c"]
    command: >
      "
      echo '[INIT] Waiting Kafka...' &&
      sleep 20 &&

      echo '[INIT] Creating topics...' &&
      /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --topic ${TOPIC_WEATHER} --bootstrap-server ${KAFKA_BOOTSTRAP} --partitions 10 --replication-factor 3 &&
      /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --topic ${TOPIC_ERROR} --bootstrap-server ${KAFKA_BOOTSTRAP} --partitions 3 --replication-factor 3 &&
      /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --topic ${TOPIC_RETRY} --bootstrap-server ${KAFKA_BOOTSTRAP} --partitions 3 --replication-factor 3 &&

      echo '[INIT] Kafka Topics Ready'
      "

  #############################################################
  # 4) KAFKA UI
  #############################################################
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: weather-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: ${KAFKA_BOOTSTRAP}
    networks:
      - project-net
    depends_on:
      - kafka-init

  #############################################################
  # 5) PRODUCER
  #############################################################
  producer-app:
    build: ./producer-app
    container_name: producer-app
    volumes:
      - ./producer-app:/app
      - ./origin-data:/app/data/origin-data
    environment:
      WATCH_DIR: ${WATCH_DIR}
      REGION_MAP_FILE: ${REGION_MAP_FILE}
      NUM_PARTITIONS: ${NUM_PARTITIONS}
      TOPIC_WEATHER: ${TOPIC_WEATHER}
      TOPIC_ERROR: ${TOPIC_ERROR}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
    networks:
      - project-net
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy

  #############################################################
  # 6) MINIO + CLIENT
  #############################################################

  minio-init:
    image: busybox
    command: rm -rf /data/*
    volumes:
      - ./minio-data:/data
    networks:
      - project-net

  minio:
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    restart: always
    networks: [project-net]
    depends_on:
      - minio-init
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - ./minio-data:/data
    command: server /data --console-address ":9001"

  mc:
    image: minio/mc:latest
    container_name: minio-client
    networks:
      - project-net
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
        sleep 5;
        mc alias set myminio ${MINIO_ENDPOINT} ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD};
        mc mb myminio/${MINIO_BUCKET} || true;
        tail -f /dev/null
      "

  #############################################################
  # 7) CONSUMER - MINIO SAVE
  #############################################################
  consumer-app-minio-save:
    build: ./consumer-app-minio-save
    container_name: consumer-app-minio-save
    volumes:
      - ./consumer-app-minio-save:/app
    networks:
      - project-net
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      minio:
        condition: service_started
    environment:
      MINIO_BUCKET: ${MINIO_BUCKET}
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
      MINIO_ENDPOINT: ${MINIO_ENDPOINT}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      TOPIC_WEATHER: ${TOPIC_WEATHER}

  #############################################################
  # 8) SPARK
  #############################################################
  spark-master:
    build: ./spark-master
    container_name: spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
    environment:
      SPARK_MODE: master
    networks:
      - project-net
    volumes:
      - spark-checkpoints:/shared-checkpoints

  spark-worker:
    build: ./spark-worker
    container_name: spark-worker
    depends_on:
      - spark-master
    networks:
      - project-net
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
    volumes:
      - spark-checkpoints:/shared-checkpoints

  #############################################################
  # 9) CONSUMER ALARM (Spark Structured Streaming Driver)
  #############################################################
  consumer-app-alarm:
    build: ./consumer-app-alarm
    container_name: consumer-app-alarm
    user: "1001:1001"
    networks:
      - project-net
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      spark-master:
        condition: service_started
      spark-worker:
        condition: service_started
      postgres:
        condition: service_started
    volumes:
      - ./consumer-app-alarm:/app
      - spark-checkpoints:/shared-checkpoints
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      TOPIC_WEATHER: ${TOPIC_WEATHER}
      TOPIC_RETRY: ${TOPIC_RETRY}

  #############################################################
  # 10) CONSUMER RETRY
  #############################################################
  consumer-app-retry:
    build: ./consumer-app-retry
    container_name: consumer-app-retry
    networks:
      - project-net
    volumes:
      - ./consumer-app-retry:/app
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_started
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      TOPIC_RETRY: ${TOPIC_RETRY}
      TOPIC_ERROR: ${TOPIC_ERROR}
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}

  #############################################################
  # 11) CONSUMER ERROR
  #############################################################
  consumer-app-error:
    build: ./consumer-app-error
    container_name: consumer-app-error
    networks:
      - project-net
    volumes:
      - ./consumer-app-error:/app
    depends_on:
      kafka-1:
        condition: service_healthy
      kafka-2:
        condition: service_healthy
      kafka-3:
        condition: service_healthy
      postgres:
        condition: service_started
    environment:
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      KAFKA_BOOTSTRAP: ${KAFKA_BOOTSTRAP}
      TOPIC_ERROR: ${TOPIC_ERROR}

  #############################################################
  # 12) POSTGRES
  #############################################################
  postgres:
    build: ./postgres
    container_name: postgres
    networks:
      - project-net
    ports:
      - "5432:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data
      - ./postgres/init-db:/docker-entrypoint-initdb.d
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}

  #############################################################
  # 13) AIRFLOW
  #############################################################
  airflow-init:
    <<: *airflow-build
    container_name: airflow-init
    entrypoint: ["/bin/bash", "/opt/airflow/entrypoint-init.sh"]
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      AIRFLOW_CONN_POSTGRES_DEFAULT: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    depends_on:
      - postgres
    networks:
      - project-net
    volumes:
      - ./airflow/entrypoint-init.sh:/opt/airflow/entrypoint-init.sh
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins

  airflow-webserver:
    <<: *airflow-build
    container_name: airflow-webserver
    networks:
      - project-net
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: ["airflow", "webserver"]
    ports:
      - "8088:8080"
  
  airflow-scheduler:
    <<: *airflow-build
    container_name: airflow-scheduler
    networks:
      - project-net
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: ["airflow", "scheduler"]


#############################################################
# NETWORKS & VOLUMES
#############################################################
networks:
  project-net:
    driver: bridge
    name: project-net

volumes:
  pgdata:
  spark-checkpoints:
