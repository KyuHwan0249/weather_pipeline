version: "3.9"

x-airflow-build: &airflow-build
  build:
    context: ./airflow
  image: custom-airflow:latest

services:
  create-origin-data-app:
    build: ./create-origin-data-app
    container_name: create-origin-data-app
    volumes:
      - ./kaggle-data:/app/data/kaggle
      - ./origin-data:/app/data/output
      - ./create-origin-data-app/main.py:/app/main.py
    environment:
      - PYTHONUNBUFFERED=1
      - drop_interval=3
      - row_interval=60
    restart: on-failure
    depends_on:
      - producer-app
    networks:
      - project-net

  # -----------------------------
  # Kafka Broker 1
  # -----------------------------
  kafka-1:
    image: apache/kafka:3.7.0
    container_name: kafka-1
    hostname: kafka-1
    networks:
      project-net:
        aliases:
          - kafka-1
    ports:
      - "9092:9092"
    volumes:
      - ./kafka/server-1.properties:/opt/kafka/config/kraft/server.properties
      - ./kafka/data/broker1:/var/lib/kafka/data
    command: >
      bash -c "/opt/kafka/bin/kafka-storage.sh format -t cluster-id-1 -c /opt/kafka/config/kraft/server.properties --ignore-formatted &&
               /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/kraft/server.properties"

  # -----------------------------
  # Kafka Broker 2
  # -----------------------------
  kafka-2:
    image: apache/kafka:3.7.0
    container_name: kafka-2
    hostname: kafka-2
    networks:
      project-net:
        aliases:
          - kafka-2
    ports:
      - "9093:9092"
    volumes:
      - ./kafka/server-2.properties:/opt/kafka/config/kraft/server.properties
      - ./kafka/data/broker2:/var/lib/kafka/data
    command: >
      bash -c "/opt/kafka/bin/kafka-storage.sh format -t cluster-id-1 -c /opt/kafka/config/kraft/server.properties --ignore-formatted &&
               /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/kraft/server.properties"

  # -----------------------------
  # Kafka Broker 3
  # -----------------------------
  kafka-3:
    image: apache/kafka:3.7.0
    container_name: kafka-3
    hostname: kafka-3
    networks:
      project-net:
        aliases:
          - kafka-3
    ports:
      - "9094:9092"
    volumes:
      - ./kafka/server-3.properties:/opt/kafka/config/kraft/server.properties
      - ./kafka/data/broker3:/var/lib/kafka/data
    command: >
      bash -c "/opt/kafka/bin/kafka-storage.sh format -t cluster-id-1 -c /opt/kafka/config/kraft/server.properties --ignore-formatted &&
               /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/kraft/server.properties"

  # -----------------------------
  # Kafka 초기화 (토픽 생성)
  # -----------------------------
  kafka-init:
    image: apache/kafka:3.7.0
    container_name: kafka-init
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    entrypoint: ["/bin/bash", "-c"]
    networks:
      - project-net
    command: >
      "
      echo '[INIT] Waiting for Kafka brokers...' &&
      sleep 20 &&
      echo '[INIT] Deleting old topics...' &&
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka-1:9092,kafka-2:9092,kafka-3:9092 --delete --topic weather-data || true &&
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka-1:9092,kafka-2:9092,kafka-3:9092 --delete --topic error-data || true &&
      echo '[INIT] Creating topics...' &&
      sleep 5 &&
      /opt/kafka/bin/kafka-topics.sh --create --topic weather-data --bootstrap-server kafka-1:9092,kafka-2:9092,kafka-3:9092 --partitions 10 --replication-factor 3 &&
      /opt/kafka/bin/kafka-topics.sh --create --topic error-data --bootstrap-server kafka-1:9092,kafka-2:9092,kafka-3:9092 --partitions 3 --replication-factor 3 &&
      echo '[INIT] Kafka topics recreated successfully ✅' &&
      exit 0
      "

  # -----------------------------
  # Kafka UI
  # -----------------------------
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=weather-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka-1:9092,kafka-2:9092,kafka-3:9092
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    networks:
      - project-net
  
  # -----------------------------
  producer-app:
    build: ./producer-app
    container_name: producer-app
    volumes:
      - ./origin-data:/app/data/origin-data
      - ./producer-app/main.py:/app/main.py
      - ./producer-app:/app
    environment:
      - check_interval=5
    depends_on:
      kafka-init:
        condition: service_completed_successfully
    networks: [project-net]
    restart: on-failure

# -----------------------------
  # MinIO (Object Storage)
  # -----------------------------
  minio-init:
    image: busybox
    command: rm -rf /data/*
    volumes:
      - ./minio-data:/data

  minio:
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    restart: always
    depends_on:
      - minio-init
    environment:
      - MINIO_ROOT_USER=minioadmin       # Access Key
      - MINIO_ROOT_PASSWORD=minioadmin   # Secret Key
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"   # S3 API endpoint
      - "9001:9001"   # Web Console (UI)
    volumes:
      - ./minio-data:/data
    networks:
      - project-net

  # -----------------------------
  # MinIO Client (옵션)
  # -----------------------------
  mc:
    image: minio/mc:latest
    container_name: minio-client
    depends_on:
      - minio
    networks:
      - project-net
    entrypoint: >
      /bin/sh -c "
      sleep 5;
      mc alias set myminio http://minio:9000 minioadmin minioadmin;
      mc mb myminio/weather-bucket || true;
      echo '[INIT] MinIO bucket weather-bucket ready ✅';
      tail -f /dev/null
      "
  # -----------------------------
  consumer-app-minio-save:
    build: ./consumer-app-minio-save
    container_name: consumer-app-minio-save
    volumes:
      - ./consumer-app-minio-save/main.py:/app/main.py
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      minio:
        condition: service_started
    networks:
      - project-net
    restart: on-failure

  # -----------------------------
  # Spark Cluster
  # -----------------------------
  spark-master:
    build:
      context: ./spark
    image: custom-spark:3.5.6
    environment:
      - SPARK_MODE=master
    ports:
      - "8081:8080"
      - "7077:7077"
    volumes:
      - spark-checkpoints:/shared-checkpoints
    networks:
      - project-net

  spark-worker:
    build:
      context: ./spark
    image: custom-spark:3.5.6
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    depends_on:
      - spark-master
    volumes:
    - spark-checkpoints:/shared-checkpoints
    networks:
      - project-net

# -----------------------------
# Consumer-App-Alarm
# -----------------------------

  consumer-app-alarm:
    user: "1001:1001"
    build: 
      context: ./consumer-app-alarm
    container_name: consumer-app-alarm
    volumes:
      - ./consumer-app-alarm/main.py:/app/main.py
      - ./consumer-app-alarm/db:/app/db
      - spark-checkpoints:/shared-checkpoints
    depends_on:
      spark-master:
        condition: service_started
      kafka-init:
        condition: service_completed_successfully
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: weatherdb
      POSTGRES_USER: weather
      POSTGRES_PASSWORD: weather123
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
    networks:
      - project-net

# -----------------------------
# PostgreSQL
# -----------------------------
  postgres:
    build:
      context: ./postgres
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: weather
      POSTGRES_PASSWORD: weather123
      POSTGRES_DB: weatherdb
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data 
      - ./postgres/init-db:/docker-entrypoint-initdb.d
    networks:
      - project-net

# -----------------------------
# Airflow
# -----------------------------
  airflow-init:
    <<: *airflow-build
    container_name: airflow-init
    entrypoint: /bin/bash
    command: -c "airflow db init && airflow users create \
        --username admin --password admin --firstname admin --lastname admin \
        --role Admin --email admin@example.com"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://weather:weather123@postgres/weatherdb
      AIRFLOW_CONN_POSTGRES_DEFAULT: postgres://weather:weather123@postgres:5432/weatherdb
    depends_on:
      - postgres
    networks:
      - project-net

  airflow-webserver:
    <<: *airflow-build
    container_name: airflow-webserver
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://weather:weather123@postgres/weatherdb
      AIRFLOW_CONN_POSTGRES_DEFAULT: postgres://weather:weather123@postgres:5432/weatherdb
    ports:
      - "8088:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: webserver
    networks:
      - project-net

  airflow-scheduler:
    <<: *airflow-build
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://weather:weather123@postgres/weatherdb
      AIRFLOW_CONN_POSTGRES_DEFAULT: postgres://weather:weather123@postgres:5432/weatherdb
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: scheduler
    networks:
      - project-net

  consumer-app-error:
    build: ./consumer-app-error
    container_name: consumer-app-error
    volumes:
      - ./consumer-app-error/main.py:/app/main.py     # ⬅ python main 덮어쓰기
      - ./consumer-app-error/db:/app/db              # DB 모듈도 같이 mount 가능
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      postgres:
        condition: service_started
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: weatherdb
      POSTGRES_USER: weather
      POSTGRES_PASSWORD: weather123
    networks:
      - project-net
    restart: always


# -----------------------------
# 공용 네트워크
# -----------------------------
networks:
  project-net:
    driver: bridge
    name: project-net
    attachable: true

volumes:
  pgdata:
  spark-checkpoints: